{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Model Training**\n",
    "This notebook focuses on model training."
   ],
   "id": "68f43300ca42b17a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Accuracy-trained models"
   ],
   "id": "15db58621374da8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 3. Naive Bayes"
   ],
   "id": "5e7bc53f1b00b598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    # Split data into train and test folds\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    nb_model.fit(X_train_scaled, y_train)\n",
    "    score = nb_model.score(X_test_scaled, y_test)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, stratify=y_balanced,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "3a97608d5a3f8cec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 4. Bayesian network"
   ],
   "id": "486c5765fa09231e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "\n",
    "def fit_bayesian_network(X_train, y_train):\n",
    "    model = BayesianNetwork([('HighBP', 'Diabetes_binary'),\n",
    "                             ('HighChol', 'Diabetes_binary'),\n",
    "                             ('BMI', 'Diabetes_binary'),\n",
    "                             ('Smoker', 'Diabetes_binary'),\n",
    "                             ('Diabetes_binary', 'BMI')])\n",
    "\n",
    "    cpd_highbp = TabularCPD(variable='HighBP', variable_card=2, values=[[0.8], [0.2]])\n",
    "    cpd_highchol = TabularCPD(variable='HighChol', variable_card=2, values=[[0.7], [0.3]])\n",
    "    cpd_bmi = TabularCPD(variable='BMI', variable_card=2, values=[[0.5], [0.5]])\n",
    "    cpd_smoker = TabularCPD(variable='Smoker', variable_card=2, values=[[0.4], [0.6]])\n",
    "    cpd_diabetes = TabularCPD(variable='Diabetes_binary', variable_card=2,\n",
    "                              values=[[0.7, 0.3], [0.3, 0.7]],\n",
    "                              evidence=['HighBP', 'HighChol', 'BMI', 'Smoker'],\n",
    "                              evidence_card=[2, 2, 2, 2])\n",
    "\n",
    "    model.add_cpds(cpd_highbp, cpd_highchol, cpd_bmi, cpd_smoker, cpd_diabetes)\n",
    "\n",
    "    model.check_model()\n",
    "\n",
    "    inference = VariableElimination(model)\n",
    "\n",
    "    return model, inference\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model, inference = fit_bayesian_network(X_train_scaled, y_train)\n",
    "\n",
    "    prediction = inference.predict(X_test_scaled)\n",
    "    predicted_labels = prediction['Diabetes_binary']\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    cv_scores.append(accuracy)\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores (Bayesian Network): {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "model, inference = fit_bayesian_network(X_train_scaled, y_train)\n",
    "\n",
    "prediction = inference.predict(X_test_scaled)\n",
    "predicted_labels = prediction['Diabetes_binary']\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"Test Set Accuracy (Bayesian Network): {test_accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predicted_labels))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted_labels))"
   ],
   "id": "83d0b618bbd63e2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 5. Neural network (automatic)"
   ],
   "id": "8c6b1063dd5d966d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# to-do",
   "id": "48496d206fdb785c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 6. Neural network (not automatic)"
   ],
   "id": "cba3e2f172dc49b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "num_hidden_layers = 2  # 1 or 2\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    if num_hidden_layers == 2:\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    cv_scores.append(scores[1])\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "if num_hidden_layers == 2:\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "1739e0527b67c697"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 7. Deep learning"
   ],
   "id": "d3028e962c163fe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:49:47.776781Z",
     "start_time": "2025-01-06T11:49:41.544450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    cv_scores.append(scores[1])\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "5558ebfb3a17b193",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 12:49:41.851679: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StandardScaler\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m classification_report, confusion_matrix, accuracy_score\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense, Dropout\n\u001B[1;32m     11\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([x, y], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras/__init__.py:21\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minput_layer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras/models/__init__.py:18\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Functional\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras/engine/functional.py:24\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layout_map \u001B[38;5;28;01mas\u001B[39;00m layout_map_lib\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/__init__.py:51\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bitwise\n\u001B[0;32m---> 51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/_api/v2/compat/__init__.py:37\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Compatibility functions.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mThe `tf.compat` module contains two sets of compatibility functions.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v1\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v2\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m forward_compatibility_horizon\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/__init__.py:31\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bitwise\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py:38\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v1\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v2\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m forward_compatibility_horizon\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m forward_compatible\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py:28\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-bad-import-order\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __internal__\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __operators__\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m audio\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v2/__init__.py:33\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bitwise\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py:38\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v1\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v2\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m forward_compatibility_horizon\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m forward_compatible\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py:332\u001B[0m\n\u001B[1;32m    330\u001B[0m _current_module \u001B[38;5;241m=\u001B[39m _sys\u001B[38;5;241m.\u001B[39mmodules[\u001B[38;5;18m__name__\u001B[39m]\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 332\u001B[0m   \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary\n\u001B[1;32m    333\u001B[0m   _current_module\u001B[38;5;241m.\u001B[39m__path__ \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    334\u001B[0m       [_module_util\u001B[38;5;241m.\u001B[39mget_parent_dir(summary)] \u001B[38;5;241m+\u001B[39m _current_module\u001B[38;5;241m.\u001B[39m__path__)\n\u001B[1;32m    335\u001B[0m   \u001B[38;5;28msetattr\u001B[39m(_current_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary\u001B[39m\u001B[38;5;124m\"\u001B[39m, summary)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/summary/__init__.py:22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# If the V1 summary API is accessible, load and re-export it here.\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 22\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummary\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v1  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/summary/v1.py:23\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary \u001B[38;5;28;01mas\u001B[39;00m _audio_summary\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcustom_scalar\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary \u001B[38;5;28;01mas\u001B[39;00m _custom_scalar_summary\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhistogram\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary \u001B[38;5;28;01mas\u001B[39;00m _histogram_summary\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary \u001B[38;5;28;01mas\u001B[39;00m _image_summary\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpr_curve\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary \u001B[38;5;28;01mas\u001B[39;00m _pr_curve_summary\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/plugins/histogram/summary.py:35\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhistogram\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m metadata\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhistogram\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary_v2\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Export V3 versions.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m histogram \u001B[38;5;241m=\u001B[39m summary_v2\u001B[38;5;241m.\u001B[39mhistogram\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/plugins/histogram/summary_v2.py:35\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhistogram\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m metadata\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m lazy_tensor_creator\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_util\n\u001B[1;32m     38\u001B[0m DEFAULT_BUCKET_COUNT \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30\u001B[39m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhistogram_pb\u001B[39m(tag, data, buckets\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, description\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/util/tensor_util.py:20\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_pb2\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtensorflow_stub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes, compat, tensor_shape\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mExtractBitsFromFloat16\u001B[39m(x):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(x, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat16)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint16)\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/__init__.py:22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmeta_graph_pb2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummary_pb2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m as_dtype  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DType  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m string  \u001B[38;5;66;03m# noqa\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:19\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Library of dtypes (Tensor element types).\"\"\"\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m types_pb2\n\u001B[1;32m     22\u001B[0m _np_bfloat16 \u001B[38;5;241m=\u001B[39m pywrap_tensorflow\u001B[38;5;241m.\u001B[39mTF_bfloat16_type()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/pywrap_tensorflow.py:22\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstruct\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m errors\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gfile\n\u001B[1;32m     25\u001B[0m TFE_DEVICE_PLACEMENT_WARN \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     26\u001B[0m TFE_DEVICE_PLACEMENT_SILENT_FOR_INT32 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/io/__init__.py:17\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gfile\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py:40\u001B[0m\n\u001B[1;32m     37\u001B[0m     S3_ENABLED \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfsspec\u001B[39;00m\n\u001B[1;32m     42\u001B[0m     FSSPEC_ENABLED \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/fsspec/__init__.py:69\u001B[0m\n\u001B[1;32m     57\u001B[0m                 registered_names[name] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     58\u001B[0m                 register_implementation(\n\u001B[1;32m     59\u001B[0m                     name,\n\u001B[1;32m     60\u001B[0m                     spec\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m                     clobber\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     66\u001B[0m                 )\n\u001B[0;32m---> 69\u001B[0m \u001B[43mprocess_entries\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/fsspec/__init__.py:43\u001B[0m, in \u001B[0;36mprocess_entries\u001B[0;34m()\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m entry_points \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 43\u001B[0m         eps \u001B[38;5;241m=\u001B[39m \u001B[43mentry_points\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# importlib-metadata < 0.8\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/importlib/metadata/__init__.py:1021\u001B[0m, in \u001B[0;36mentry_points\u001B[0;34m(**params)\u001B[0m\n\u001B[1;32m   1017\u001B[0m unique \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mpartial(unique_everseen, key\u001B[38;5;241m=\u001B[39mnorm_name)\n\u001B[1;32m   1018\u001B[0m eps \u001B[38;5;241m=\u001B[39m itertools\u001B[38;5;241m.\u001B[39mchain\u001B[38;5;241m.\u001B[39mfrom_iterable(\n\u001B[1;32m   1019\u001B[0m     dist\u001B[38;5;241m.\u001B[39mentry_points \u001B[38;5;28;01mfor\u001B[39;00m dist \u001B[38;5;129;01min\u001B[39;00m unique(distributions())\n\u001B[1;32m   1020\u001B[0m )\n\u001B[0;32m-> 1021\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSelectableGroups\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/importlib/metadata/__init__.py:459\u001B[0m, in \u001B[0;36mSelectableGroups.load\u001B[0;34m(cls, eps)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;28mcls\u001B[39m, eps):\n\u001B[1;32m    458\u001B[0m     by_group \u001B[38;5;241m=\u001B[39m operator\u001B[38;5;241m.\u001B[39mattrgetter(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgroup\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 459\u001B[0m     ordered \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_group\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m     grouped \u001B[38;5;241m=\u001B[39m itertools\u001B[38;5;241m.\u001B[39mgroupby(ordered, by_group)\n\u001B[1;32m    461\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m((group, EntryPoints(eps)) \u001B[38;5;28;01mfor\u001B[39;00m group, eps \u001B[38;5;129;01min\u001B[39;00m grouped)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/importlib/metadata/__init__.py:1019\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1016\u001B[0m norm_name \u001B[38;5;241m=\u001B[39m operator\u001B[38;5;241m.\u001B[39mattrgetter(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_normalized_name\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1017\u001B[0m unique \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mpartial(unique_everseen, key\u001B[38;5;241m=\u001B[39mnorm_name)\n\u001B[1;32m   1018\u001B[0m eps \u001B[38;5;241m=\u001B[39m itertools\u001B[38;5;241m.\u001B[39mchain\u001B[38;5;241m.\u001B[39mfrom_iterable(\n\u001B[0;32m-> 1019\u001B[0m     \u001B[43mdist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentry_points\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m dist \u001B[38;5;129;01min\u001B[39;00m unique(distributions())\n\u001B[1;32m   1020\u001B[0m )\n\u001B[1;32m   1021\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m SelectableGroups\u001B[38;5;241m.\u001B[39mload(eps)\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/importlib/metadata/__init__.py:631\u001B[0m, in \u001B[0;36mDistribution.entry_points\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mentry_points\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 631\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m EntryPoints\u001B[38;5;241m.\u001B[39m_from_text_for(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_text\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mentry_points.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/importlib/metadata/__init__.py:927\u001B[0m, in \u001B[0;36mPathDistribution.read_text\u001B[0;34m(self, filename)\u001B[0m\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_text\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename):\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m suppress(\n\u001B[1;32m    921\u001B[0m         \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m,\n\u001B[1;32m    922\u001B[0m         \u001B[38;5;167;01mIsADirectoryError\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    925\u001B[0m         \u001B[38;5;167;01mPermissionError\u001B[39;00m,\n\u001B[1;32m    926\u001B[0m     ):\n\u001B[0;32m--> 927\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_path\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoinpath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/pathlib.py:1135\u001B[0m, in \u001B[0;36mPath.read_text\u001B[0;34m(self, encoding, errors)\u001B[0m\n\u001B[1;32m   1133\u001B[0m encoding \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mtext_encoding(encoding)\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopen(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m-> 1135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/codecs.py:319\u001B[0m, in \u001B[0;36mBufferedIncrementalDecoder.decode\u001B[0;34m(self, input, final)\u001B[0m\n\u001B[1;32m    314\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_buffer_decode\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, errors, final):\n\u001B[1;32m    315\u001B[0m     \u001B[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001B[39;00m\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;66;03m# and return an (output, length consumed) tuple\u001B[39;00m\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n\u001B[0;32m--> 319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;66;03m# decode input (taking the buffer into account)\u001B[39;00m\n\u001B[1;32m    321\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer \u001B[38;5;241m+\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[1;32m    322\u001B[0m     (result, consumed) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer_decode(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merrors, final)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 8. SVM"
   ],
   "id": "d8975785c15bf10e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)  # Adjust the fraction as needed\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)  # Adjust the fraction as needed\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "svm_clf = LinearSVC(dual=\"auto\", random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    svm_clf.fit(X_train_scaled, y_train)\n",
    "    score = svm_clf.score(X_test_scaled, y_test)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "    y_pred_fold = svm_clf.predict(X_test_scaled)\n",
    "    y_pred_cv.extend(y_pred_fold)\n",
    "\n",
    "y_pred_cv = np.array(y_pred_cv)\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, stratify=y_balanced,\n",
    "                                                    random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_test_pred = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(test_conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ],
   "id": "ae9b3c142f6e1982"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
