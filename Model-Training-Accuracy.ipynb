{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Model Training**\n",
    "This notebook focuses on model training."
   ],
   "id": "68f43300ca42b17a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Accuracy-trained models"
   ],
   "id": "15db58621374da8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:56:25.700698Z",
     "start_time": "2025-01-06T11:56:19.972223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
    "\n",
    "x = cdc_diabetes_health_indicators.data.features\n",
    "y = cdc_diabetes_health_indicators.data.targets"
   ],
   "id": "ef21530d80956b4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Naive Bayes",
   "id": "5e7bc53f1b00b598"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:56:30.533518Z",
     "start_time": "2025-01-06T11:56:29.626160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    # Split data into train and test folds\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    nb_model.fit(X_train_scaled, y_train)\n",
    "    score = nb_model.score(X_test_scaled, y_test)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, stratify=y_balanced,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "3a97608d5a3f8cec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.71313412 0.71994441 0.72077832 0.71480195 0.71629135 0.72212955\n",
      " 0.71670837 0.7206005  0.72421462 0.7117042 ]\n",
      "Mean Accuracy: 0.72\n",
      "Standard Deviation: 0.00\n",
      "Confidence Interval: [0.71, 0.72]\n",
      "Test Set Accuracy: 0.72\n",
      "Confusion Matrix:\n",
      "[[6528 2206]\n",
      " [1822 3833]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      8734\n",
      "           1       0.63      0.68      0.66      5655\n",
      "\n",
      "    accuracy                           0.72     14389\n",
      "   macro avg       0.71      0.71      0.71     14389\n",
      "weighted avg       0.72      0.72      0.72     14389\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 4. Bayesian network"
   ],
   "id": "486c5765fa09231e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:56:41.220138Z",
     "start_time": "2025-01-06T11:56:38.624927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "\n",
    "def fit_bayesian_network():\n",
    "    model = BayesianNetwork([('HighBP', 'Diabetes_binary'),\n",
    "                             ('HighChol', 'Diabetes_binary'),\n",
    "                             ('BMI', 'Diabetes_binary'),\n",
    "                             ('Smoker', 'Diabetes_binary'),\n",
    "                             ('Diabetes_binary', 'BMI')])\n",
    "\n",
    "    cpd_highbp = TabularCPD(variable='HighBP', variable_card=2, values=[[0.8], [0.2]])\n",
    "    cpd_highchol = TabularCPD(variable='HighChol', variable_card=2, values=[[0.7], [0.3]])\n",
    "    cpd_bmi = TabularCPD(variable='BMI', variable_card=2, values=[[0.5], [0.5]])\n",
    "    cpd_smoker = TabularCPD(variable='Smoker', variable_card=2, values=[[0.4], [0.6]])\n",
    "    cpd_diabetes = TabularCPD(variable='Diabetes_binary', variable_card=2,\n",
    "                              values=[[0.7, 0.3], [0.3, 0.7]],\n",
    "                              evidence=['HighBP', 'HighChol', 'BMI', 'Smoker'],\n",
    "                              evidence_card=[2, 2, 2, 2])\n",
    "\n",
    "    model.add_cpds(cpd_highbp, cpd_highchol, cpd_bmi, cpd_smoker, cpd_diabetes)\n",
    "    model.check_model()\n",
    "    inference = VariableElimination(model)\n",
    "\n",
    "    return model, inference\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model, inference = fit_bayesian_network(y_train)\n",
    "\n",
    "    prediction = inference.predict(X_test_scaled)\n",
    "    predicted_labels = prediction['Diabetes_binary']\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    cv_scores.append(accuracy)\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores (Bayesian Network): {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "model, inference = fit_bayesian_network(y_train)\n",
    "\n",
    "prediction = inference.predict(X_test_scaled)\n",
    "predicted_labels = prediction['Diabetes_binary']\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"Test Set Accuracy (Bayesian Network): {test_accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predicted_labels))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted_labels))"
   ],
   "id": "83d0b618bbd63e2c",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StandardScaler\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m classification_report, confusion_matrix, accuracy_score\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianNetwork\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfactors\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscrete\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TabularCPD\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minference\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VariableElimination\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/models/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mBayesianNetwork\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianNetwork\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mBayesianModel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianModel\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mClusterGraph\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ClusterGraph\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/models/BayesianNetwork.py:15\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DAG\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfactors\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontinuous\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ContinuousFactor\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfactors\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscrete\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     17\u001B[0m     DiscreteFactor,\n\u001B[1;32m     18\u001B[0m     JointProbabilityDistribution,\n\u001B[1;32m     19\u001B[0m     TabularCPD,\n\u001B[1;32m     20\u001B[0m )\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mglobal_vars\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logger\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/factors/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m factor_divide, factor_product, factor_sum_product\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mFactorSet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FactorSet, factorset_divide, factorset_product\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mFactorDict\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FactorDict\n\u001B[1;32m      5\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFactorSet\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfactorset_divide\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFactorDict\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     13\u001B[0m ]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/factors/FactorDict.py:10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OrdinalEncoder\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfactors\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m factor_product\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfactors\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscrete\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DiscreteFactor\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mFactorDict\u001B[39;00m(\u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_dataframe\u001B[39m(\u001B[38;5;28mcls\u001B[39m, df, marginals):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/factors/discrete/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mDiscreteFactor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DiscreteFactor, State\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mCPD\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TabularCPD\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mJointProbabilityDistribution\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m JointProbabilityDistribution\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/factors/discrete/DiscreteFactor.py:12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfactors\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseFactor\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mglobal_vars\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logger\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpgmpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StateNameMixin, compat_fns\n\u001B[1;32m     14\u001B[0m State \u001B[38;5;241m=\u001B[39m namedtuple(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m\"\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvar\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mDiscreteFactor\u001B[39;00m(BaseFactor, StateNameMixin):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/utils/__init__.py:5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optimize, pinverse\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstate_name\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StateNameMixin\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m discretize, get_example_model, llm_pairwise_orient\n\u001B[1;32m      7\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcartesian\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample_discrete\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_pairwise_orient\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     18\u001B[0m ]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/pgmpy/utils/utils.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerativeai\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgenai\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google.generativeai'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 5. Neural network (automatic)"
   ],
   "id": "8c6b1063dd5d966d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:21:36.945173Z",
     "start_time": "2025-01-06T14:21:36.562223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Unfortunately this code gives an error, most likely due to a \"circular import\" as reported in the error, but we cannot find any files that would cause this overlap. Furthermore, it could be caused by an issue with the TensorFlow and Keras versions, but we have also revised these and cannot find any immediate problems. \n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import keras_tuner as kt\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
    "x = cdc_diabetes_health_indicators.data.features\n",
    "y = cdc_diabetes_health_indicators.data.targets\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_input', min_value=16, max_value=128, step=16),\n",
    "                    activation='relu', input_dim=X_balanced.shape[1]))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 3)): # Automatically choose the number of hidden layers (1-3)\n",
    "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=16, max_value=128, step=16),\n",
    "                        activation='relu'))\n",
    "        model.add(Dropout(rate=hp.Choice('dropout_rate', [0.2, 0.3, 0.4])))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=hp.Choice('optimizer', ['adam', 'rmsprop']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_tuning_dir',\n",
    "    project_name='binary_classification'\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    tuner.search(X_train_scaled, y_train, epochs=20, validation_split=0.2, verbose=0)\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    scores = best_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    cv_scores.append(scores[1])\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "best_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = (best_model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "48496d206fdb785c",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'keras_tuner.src.engine.base_tuner' has no attribute 'BaseTuner' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense, Dropout\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mkt\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mucimlrepo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m fetch_ucirepo\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Fetch the dataset\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/__init__.py:9\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m engine\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m errors\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m oracles\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/engine/__init__.py:8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m base_tuner\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hypermodel\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hyperparameters\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner/__init__.py:8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase_tuner\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseTuner\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:22\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtraceback\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config \u001B[38;5;28;01mas\u001B[39;00m config_module\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m errors\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/src/__init__.py:17\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m oracles\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tuners\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_tuner_export\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/src/oracles/__init__.py:15\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianOptimizationOracle\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgridsearch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GridSearchOracle\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhyperband\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HyperbandOracle\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/src/tuners/__init__.py:16\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianOptimization\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgridsearch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GridSearch\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhyperband\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Hyperband\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/src/tuners/bayesian.py:34\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m oracle \u001B[38;5;28;01mas\u001B[39;00m oracle_module\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m trial \u001B[38;5;28;01mas\u001B[39;00m trial_module\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tuner \u001B[38;5;28;01mas\u001B[39;00m tuner_module\n\u001B[1;32m     37\u001B[0m \u001B[38;5;129m@keras_tuner_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_tuner.oracles.BayesianOptimizationOracle\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mBayesianOptimizationOracle\u001B[39;00m(oracle_module\u001B[38;5;241m.\u001B[39mOracle):\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Bayesian optimization oracle.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    It uses Bayesian optimization with a underlying Gaussian process model.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m            of the retries succeeded.\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:42\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m base_tuner\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_tuner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tuner_utils\n\u001B[1;32m     35\u001B[0m \u001B[38;5;129m@keras_tuner_export\u001B[39m(\n\u001B[1;32m     36\u001B[0m     [\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_tuner.Tuner\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_tuner.tuners.Tuner\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_tuner.engine.tuner.Tuner\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     40\u001B[0m     ]\n\u001B[1;32m     41\u001B[0m )\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mTuner\u001B[39;00m(\u001B[43mbase_tuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBaseTuner\u001B[49m):\n\u001B[1;32m     43\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Tuner class for Keras models.\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;03m    This is the base `Tuner` class for all tuners for Keras models. It manages\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;124;03m            not set. This is useful when resuming a previously stopped search.\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     98\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     99\u001B[0m         oracle,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    113\u001B[0m     ):\n",
      "\u001B[0;31mAttributeError\u001B[0m: partially initialized module 'keras_tuner.src.engine.base_tuner' has no attribute 'BaseTuner' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 6. Neural network (not automatic)"
   ],
   "id": "cba3e2f172dc49b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:07:48.466388Z",
     "start_time": "2025-01-06T11:56:45.351088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "num_hidden_layers = 2  # 1 or 2\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    if num_hidden_layers == 2:\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    cv_scores.append(scores[1])\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "if num_hidden_layers == 2:\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "1739e0527b67c697",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75066018 0.7449618  0.76066715 0.75149411 0.74534333 0.74589938\n",
      " 0.75229359 0.75090355 0.75771475 0.74617738]\n",
      "Mean Accuracy: 0.75\n",
      "Standard Deviation: 0.01\n",
      "Confidence Interval: [0.75, 0.76]\n",
      "Epoch 1/50\n",
      "1799/1799 [==============================] - 2s 674us/step - loss: 0.5236 - accuracy: 0.7299\n",
      "Epoch 2/50\n",
      "1799/1799 [==============================] - 1s 675us/step - loss: 0.5059 - accuracy: 0.7457\n",
      "Epoch 3/50\n",
      "1799/1799 [==============================] - 1s 684us/step - loss: 0.5021 - accuracy: 0.7476\n",
      "Epoch 4/50\n",
      "1799/1799 [==============================] - 1s 673us/step - loss: 0.5006 - accuracy: 0.7498\n",
      "Epoch 5/50\n",
      "1799/1799 [==============================] - 1s 678us/step - loss: 0.4999 - accuracy: 0.7492\n",
      "Epoch 6/50\n",
      "1799/1799 [==============================] - 1s 699us/step - loss: 0.4989 - accuracy: 0.7518\n",
      "Epoch 7/50\n",
      "1799/1799 [==============================] - 1s 669us/step - loss: 0.4977 - accuracy: 0.7518\n",
      "Epoch 8/50\n",
      "1799/1799 [==============================] - 1s 708us/step - loss: 0.4965 - accuracy: 0.7518\n",
      "Epoch 9/50\n",
      "1799/1799 [==============================] - 1s 671us/step - loss: 0.4984 - accuracy: 0.7519\n",
      "Epoch 10/50\n",
      "1799/1799 [==============================] - 1s 677us/step - loss: 0.4968 - accuracy: 0.7520\n",
      "Epoch 11/50\n",
      "1799/1799 [==============================] - 1s 678us/step - loss: 0.4963 - accuracy: 0.7519\n",
      "Epoch 12/50\n",
      "1799/1799 [==============================] - 1s 726us/step - loss: 0.4954 - accuracy: 0.7519\n",
      "Epoch 13/50\n",
      "1799/1799 [==============================] - 1s 728us/step - loss: 0.4960 - accuracy: 0.7525\n",
      "Epoch 14/50\n",
      "1799/1799 [==============================] - 1s 668us/step - loss: 0.4960 - accuracy: 0.7531\n",
      "Epoch 15/50\n",
      "1799/1799 [==============================] - 1s 669us/step - loss: 0.4949 - accuracy: 0.7535\n",
      "Epoch 16/50\n",
      "1799/1799 [==============================] - 1s 666us/step - loss: 0.4954 - accuracy: 0.7507\n",
      "Epoch 17/50\n",
      "1799/1799 [==============================] - 1s 682us/step - loss: 0.4949 - accuracy: 0.7526\n",
      "Epoch 18/50\n",
      "1799/1799 [==============================] - 1s 695us/step - loss: 0.4948 - accuracy: 0.7527\n",
      "Epoch 19/50\n",
      "1799/1799 [==============================] - 1s 676us/step - loss: 0.4942 - accuracy: 0.7528\n",
      "Epoch 20/50\n",
      "1799/1799 [==============================] - 1s 669us/step - loss: 0.4946 - accuracy: 0.7531\n",
      "Epoch 21/50\n",
      "1799/1799 [==============================] - 1s 675us/step - loss: 0.4939 - accuracy: 0.7541\n",
      "Epoch 22/50\n",
      "1799/1799 [==============================] - 1s 678us/step - loss: 0.4926 - accuracy: 0.7539\n",
      "Epoch 23/50\n",
      "1799/1799 [==============================] - 1s 669us/step - loss: 0.4931 - accuracy: 0.7536\n",
      "Epoch 24/50\n",
      "1799/1799 [==============================] - 1s 704us/step - loss: 0.4936 - accuracy: 0.7536\n",
      "Epoch 25/50\n",
      "1799/1799 [==============================] - 1s 679us/step - loss: 0.4939 - accuracy: 0.7533\n",
      "Epoch 26/50\n",
      "1799/1799 [==============================] - 1s 667us/step - loss: 0.4926 - accuracy: 0.7547\n",
      "Epoch 27/50\n",
      "1799/1799 [==============================] - 1s 690us/step - loss: 0.4926 - accuracy: 0.7538\n",
      "Epoch 28/50\n",
      "1799/1799 [==============================] - 1s 674us/step - loss: 0.4923 - accuracy: 0.7542\n",
      "Epoch 29/50\n",
      "1799/1799 [==============================] - 1s 668us/step - loss: 0.4920 - accuracy: 0.7533\n",
      "Epoch 30/50\n",
      "1799/1799 [==============================] - 1s 673us/step - loss: 0.4933 - accuracy: 0.7545\n",
      "Epoch 31/50\n",
      "1799/1799 [==============================] - 1s 668us/step - loss: 0.4930 - accuracy: 0.7543\n",
      "Epoch 32/50\n",
      "1799/1799 [==============================] - 1s 666us/step - loss: 0.4916 - accuracy: 0.7537\n",
      "Epoch 33/50\n",
      "1799/1799 [==============================] - 1s 675us/step - loss: 0.4923 - accuracy: 0.7536\n",
      "Epoch 34/50\n",
      "1799/1799 [==============================] - 1s 666us/step - loss: 0.4921 - accuracy: 0.7547\n",
      "Epoch 35/50\n",
      "1799/1799 [==============================] - 1s 669us/step - loss: 0.4916 - accuracy: 0.7537\n",
      "Epoch 36/50\n",
      "1799/1799 [==============================] - 1s 671us/step - loss: 0.4910 - accuracy: 0.7547\n",
      "Epoch 37/50\n",
      "1799/1799 [==============================] - 1s 667us/step - loss: 0.4921 - accuracy: 0.7555\n",
      "Epoch 38/50\n",
      "1799/1799 [==============================] - 1s 683us/step - loss: 0.4922 - accuracy: 0.7539\n",
      "Epoch 39/50\n",
      "1799/1799 [==============================] - 1s 679us/step - loss: 0.4911 - accuracy: 0.7542\n",
      "Epoch 40/50\n",
      "1799/1799 [==============================] - 1s 672us/step - loss: 0.4907 - accuracy: 0.7549\n",
      "Epoch 41/50\n",
      "1799/1799 [==============================] - 1s 668us/step - loss: 0.4911 - accuracy: 0.7545\n",
      "Epoch 42/50\n",
      "1799/1799 [==============================] - 1s 666us/step - loss: 0.4901 - accuracy: 0.7553\n",
      "Epoch 43/50\n",
      "1799/1799 [==============================] - 1s 669us/step - loss: 0.4903 - accuracy: 0.7551\n",
      "Epoch 44/50\n",
      "1799/1799 [==============================] - 1s 695us/step - loss: 0.4912 - accuracy: 0.7553\n",
      "Epoch 45/50\n",
      "1799/1799 [==============================] - 1s 677us/step - loss: 0.4899 - accuracy: 0.7541\n",
      "Epoch 46/50\n",
      "1799/1799 [==============================] - 1s 669us/step - loss: 0.4911 - accuracy: 0.7552\n",
      "Epoch 47/50\n",
      "1799/1799 [==============================] - 1s 700us/step - loss: 0.4896 - accuracy: 0.7553\n",
      "Epoch 48/50\n",
      "1799/1799 [==============================] - 1s 686us/step - loss: 0.4902 - accuracy: 0.7562\n",
      "Epoch 49/50\n",
      "1799/1799 [==============================] - 1s 689us/step - loss: 0.4906 - accuracy: 0.7549\n",
      "Epoch 50/50\n",
      "1799/1799 [==============================] - 1s 672us/step - loss: 0.4903 - accuracy: 0.7549\n",
      "450/450 [==============================] - 1s 406us/step\n",
      "Test Set Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      "[[7027 1707]\n",
      " [1901 3754]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      8734\n",
      "           1       0.69      0.66      0.68      5655\n",
      "\n",
      "    accuracy                           0.75     14389\n",
      "   macro avg       0.74      0.73      0.74     14389\n",
      "weighted avg       0.75      0.75      0.75     14389\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 7. Deep learning"
   ],
   "id": "d3028e962c163fe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:21:51.724067Z",
     "start_time": "2025-01-06T12:07:48.475644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    cv_scores.append(scores[1])\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "5558ebfb3a17b193",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.74829745 0.7466296  0.75649756 0.7551077  0.74603838 0.74589938\n",
      " 0.7496525  0.75159854 0.75618571 0.74756742]\n",
      "Mean Accuracy: 0.75\n",
      "Standard Deviation: 0.00\n",
      "Confidence Interval: [0.75, 0.75]\n",
      "Epoch 1/50\n",
      "1799/1799 [==============================] - 2s 727us/step - loss: 0.5213 - accuracy: 0.7335\n",
      "Epoch 2/50\n",
      "1799/1799 [==============================] - 1s 694us/step - loss: 0.5062 - accuracy: 0.7461\n",
      "Epoch 3/50\n",
      "1799/1799 [==============================] - 1s 684us/step - loss: 0.5022 - accuracy: 0.7483\n",
      "Epoch 4/50\n",
      "1799/1799 [==============================] - 1s 664us/step - loss: 0.5007 - accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "1799/1799 [==============================] - 1s 660us/step - loss: 0.5003 - accuracy: 0.7502\n",
      "Epoch 6/50\n",
      "1799/1799 [==============================] - 1s 678us/step - loss: 0.4996 - accuracy: 0.7501\n",
      "Epoch 7/50\n",
      "1799/1799 [==============================] - 1s 683us/step - loss: 0.4975 - accuracy: 0.7509\n",
      "Epoch 8/50\n",
      "1799/1799 [==============================] - 1s 732us/step - loss: 0.4981 - accuracy: 0.7502\n",
      "Epoch 9/50\n",
      "1799/1799 [==============================] - 1s 743us/step - loss: 0.4977 - accuracy: 0.7509\n",
      "Epoch 10/50\n",
      "1799/1799 [==============================] - 1s 778us/step - loss: 0.4957 - accuracy: 0.7527\n",
      "Epoch 11/50\n",
      "1799/1799 [==============================] - 1s 772us/step - loss: 0.4958 - accuracy: 0.7506\n",
      "Epoch 12/50\n",
      "1799/1799 [==============================] - 1s 765us/step - loss: 0.4954 - accuracy: 0.7529\n",
      "Epoch 13/50\n",
      "1799/1799 [==============================] - 1s 746us/step - loss: 0.4954 - accuracy: 0.7529\n",
      "Epoch 14/50\n",
      "1799/1799 [==============================] - 1s 765us/step - loss: 0.4942 - accuracy: 0.7531\n",
      "Epoch 15/50\n",
      "1799/1799 [==============================] - 1s 760us/step - loss: 0.4939 - accuracy: 0.7518\n",
      "Epoch 16/50\n",
      "1799/1799 [==============================] - 1s 759us/step - loss: 0.4951 - accuracy: 0.7535\n",
      "Epoch 17/50\n",
      "1799/1799 [==============================] - 1s 784us/step - loss: 0.4943 - accuracy: 0.7525\n",
      "Epoch 18/50\n",
      "1799/1799 [==============================] - 3s 2ms/step - loss: 0.4945 - accuracy: 0.7528\n",
      "Epoch 19/50\n",
      "1799/1799 [==============================] - 2s 931us/step - loss: 0.4941 - accuracy: 0.7532\n",
      "Epoch 20/50\n",
      "1799/1799 [==============================] - 1s 748us/step - loss: 0.4943 - accuracy: 0.7528\n",
      "Epoch 21/50\n",
      "1799/1799 [==============================] - 1s 767us/step - loss: 0.4934 - accuracy: 0.7535\n",
      "Epoch 22/50\n",
      "1799/1799 [==============================] - 1s 752us/step - loss: 0.4934 - accuracy: 0.7537\n",
      "Epoch 23/50\n",
      "1799/1799 [==============================] - 189s 105ms/step - loss: 0.4932 - accuracy: 0.7531\n",
      "Epoch 24/50\n",
      "1799/1799 [==============================] - 2s 1ms/step - loss: 0.4938 - accuracy: 0.7541\n",
      "Epoch 25/50\n",
      "1799/1799 [==============================] - 1s 761us/step - loss: 0.4933 - accuracy: 0.7529\n",
      "Epoch 26/50\n",
      "1799/1799 [==============================] - 1s 761us/step - loss: 0.4932 - accuracy: 0.7543\n",
      "Epoch 27/50\n",
      "1799/1799 [==============================] - 1s 784us/step - loss: 0.4932 - accuracy: 0.7544\n",
      "Epoch 28/50\n",
      "1799/1799 [==============================] - 1s 811us/step - loss: 0.4926 - accuracy: 0.7541\n",
      "Epoch 29/50\n",
      "1799/1799 [==============================] - 4s 2ms/step - loss: 0.4920 - accuracy: 0.7540\n",
      "Epoch 30/50\n",
      "1799/1799 [==============================] - 1s 758us/step - loss: 0.4927 - accuracy: 0.7542\n",
      "Epoch 31/50\n",
      "1799/1799 [==============================] - 1s 771us/step - loss: 0.4915 - accuracy: 0.7541\n",
      "Epoch 32/50\n",
      "1799/1799 [==============================] - 1s 728us/step - loss: 0.4925 - accuracy: 0.7537\n",
      "Epoch 33/50\n",
      "1799/1799 [==============================] - 1s 728us/step - loss: 0.4924 - accuracy: 0.7537\n",
      "Epoch 34/50\n",
      "1799/1799 [==============================] - 1s 756us/step - loss: 0.4924 - accuracy: 0.7533\n",
      "Epoch 35/50\n",
      "1799/1799 [==============================] - 1s 725us/step - loss: 0.4921 - accuracy: 0.7548\n",
      "Epoch 36/50\n",
      "1799/1799 [==============================] - 1s 731us/step - loss: 0.4919 - accuracy: 0.7544\n",
      "Epoch 37/50\n",
      "1799/1799 [==============================] - 1s 737us/step - loss: 0.4911 - accuracy: 0.7550\n",
      "Epoch 38/50\n",
      "1799/1799 [==============================] - 1s 733us/step - loss: 0.4915 - accuracy: 0.7554\n",
      "Epoch 39/50\n",
      "1799/1799 [==============================] - 1s 729us/step - loss: 0.4920 - accuracy: 0.7554\n",
      "Epoch 40/50\n",
      "1799/1799 [==============================] - 1s 727us/step - loss: 0.4909 - accuracy: 0.7548\n",
      "Epoch 41/50\n",
      "1799/1799 [==============================] - 1s 759us/step - loss: 0.4907 - accuracy: 0.7556\n",
      "Epoch 42/50\n",
      "1799/1799 [==============================] - 1s 736us/step - loss: 0.4914 - accuracy: 0.7550\n",
      "Epoch 43/50\n",
      "1799/1799 [==============================] - 1s 732us/step - loss: 0.4910 - accuracy: 0.7544\n",
      "Epoch 44/50\n",
      "1799/1799 [==============================] - 1s 726us/step - loss: 0.4912 - accuracy: 0.7548\n",
      "Epoch 45/50\n",
      "1799/1799 [==============================] - 1s 734us/step - loss: 0.4907 - accuracy: 0.7542\n",
      "Epoch 46/50\n",
      "1799/1799 [==============================] - 1s 733us/step - loss: 0.4908 - accuracy: 0.7551\n",
      "Epoch 47/50\n",
      "1799/1799 [==============================] - 1s 734us/step - loss: 0.4908 - accuracy: 0.7559\n",
      "Epoch 48/50\n",
      "1799/1799 [==============================] - 1s 782us/step - loss: 0.4915 - accuracy: 0.7534\n",
      "Epoch 49/50\n",
      "1799/1799 [==============================] - 1s 696us/step - loss: 0.4908 - accuracy: 0.7554\n",
      "Epoch 50/50\n",
      "1799/1799 [==============================] - 1s 619us/step - loss: 0.4903 - accuracy: 0.7554\n",
      "450/450 [==============================] - 0s 418us/step\n",
      "Test Set Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      "[[6941 1793]\n",
      " [1804 3851]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      8734\n",
      "           1       0.68      0.68      0.68      5655\n",
      "\n",
      "    accuracy                           0.75     14389\n",
      "   macro avg       0.74      0.74      0.74     14389\n",
      "weighted avg       0.75      0.75      0.75     14389\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "<br><br>\n",
    "### 8. SVM"
   ],
   "id": "d8975785c15bf10e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:50:43.263368Z",
     "start_time": "2025-01-06T13:50:42.345288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "svm_clf = LinearSVC(dual=\"auto\", random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    svm_clf.fit(X_train_scaled, y_train)\n",
    "    score = svm_clf.score(X_test_scaled, y_test)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "    y_pred_fold = svm_clf.predict(X_test_scaled)\n",
    "    y_pred_cv.extend(y_pred_fold)\n",
    "\n",
    "y_pred_cv = np.array(y_pred_cv)\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "conf_interval_lower = mean_accuracy - std_dev\n",
    "conf_interval_upper = mean_accuracy + std_dev\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"Confidence Interval: [{conf_interval_lower:.2f}, {conf_interval_upper:.2f}]\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, stratify=y_balanced,\n",
    "                                                    random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_test_pred = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(test_conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ],
   "id": "ae9b3c142f6e1982",
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'dual' parameter of LinearSVC must be an instance of 'bool', an instance of 'numpy.bool_' or an instance of 'int'. Got 'auto' instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidParameterError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 41\u001B[0m\n\u001B[1;32m     38\u001B[0m X_train_scaled[columns_to_normalize] \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mfit_transform(X_train[columns_to_normalize])\n\u001B[1;32m     39\u001B[0m X_test_scaled[columns_to_normalize] \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mtransform(X_test[columns_to_normalize])\n\u001B[0;32m---> 41\u001B[0m \u001B[43msvm_clf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m score \u001B[38;5;241m=\u001B[39m svm_clf\u001B[38;5;241m.\u001B[39mscore(X_test_scaled, y_test)\n\u001B[1;32m     43\u001B[0m cv_scores\u001B[38;5;241m.\u001B[39mappend(score)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/sklearn/svm/_classes.py:261\u001B[0m, in \u001B[0;36mLinearSVC.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model according to the given training data.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \n\u001B[1;32m    240\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;124;03m        An instance of the estimator.\u001B[39;00m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[1;32m    264\u001B[0m         X,\n\u001B[1;32m    265\u001B[0m         y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    269\u001B[0m         accept_large_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    270\u001B[0m     )\n\u001B[1;32m    271\u001B[0m     check_classification_targets(y)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/sklearn/base.py:600\u001B[0m, in \u001B[0;36mBaseEstimator._validate_params\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    593\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001B[39;00m\n\u001B[1;32m    594\u001B[0m \n\u001B[1;32m    595\u001B[0m \u001B[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;124;03m    accepted constraints.\u001B[39;00m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 600\u001B[0m     \u001B[43mvalidate_parameter_constraints\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parameter_constraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcaller_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/diabetes_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:97\u001B[0m, in \u001B[0;36mvalidate_parameter_constraints\u001B[0;34m(parameter_constraints, params, caller_name)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     92\u001B[0m     constraints_str \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     93\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;28mstr\u001B[39m(c)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mconstraints[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     94\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     95\u001B[0m     )\n\u001B[0;32m---> 97\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m InvalidParameterError(\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_name\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m parameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcaller_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_val\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    100\u001B[0m )\n",
      "\u001B[0;31mInvalidParameterError\u001B[0m: The 'dual' parameter of LinearSVC must be an instance of 'bool', an instance of 'numpy.bool_' or an instance of 'int'. Got 'auto' instead."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ada3de3409be1ed8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
