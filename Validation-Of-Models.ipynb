{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Validation of Models**\n",
    "This notebook focuses on the validation of models by analyzing both their accuracy and cost-based performance."
   ],
   "id": "3afb54435590630a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Accuracy-based performance"
   ],
   "id": "a78d7c4f28dd71cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:45:04.354546Z",
     "start_time": "2025-01-06T21:45:00.456673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
    "\n",
    "x = cdc_diabetes_health_indicators.data.features\n",
    "y = cdc_diabetes_health_indicators.data.targets"
   ],
   "id": "9adcb76069f29092",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Naive Bayes",
   "id": "507bb954900c532a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:45:08.077396Z",
     "start_time": "2025-01-06T21:45:06.923996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "cost_matrix = np.array([[0, 10], [1, 0]])\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "for train_index, test_index in skf.split(X_balanced, y_balanced):\n",
    "    X_train_fold, X_val_fold = X_balanced.iloc[train_index], X_balanced.iloc[test_index]\n",
    "    y_train_fold, y_val_fold = y_balanced.iloc[train_index], y_balanced.iloc[test_index]\n",
    "\n",
    "    nb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    y_pred_fold = nb_model.predict(X_val_fold)\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_val_fold, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len (y_val_fold)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation:\", np.std(cost_scores_per_instance))"
   ],
   "id": "82d00d3ed632c361",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7180307386879229\n",
      "Standard deviation: 0.003899447448175181\n",
      "Mean cost: 10399.5\n",
      "Standard deviation: 176.26868695261788\n",
      "Mean cost: 1.44557964970809\n",
      "Standard deviation: 0.024502180560552953\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Neural network with number of hidden layers automatically chosen",
   "id": "dd0144b194cc9829"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T10:13:01.977515Z",
     "start_time": "2025-01-07T10:06:52.616617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_input', min_value=32, max_value=128, step=32),\n",
    "                    input_dim=X_train_scaled.shape[1],\n",
    "                    activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('num_hidden_layers', 1, 3)):  # 1 to 3 hidden layers\n",
    "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=128, step=32),\n",
    "                        activation='relu'))\n",
    "        model.add(Dropout(hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 1e-4, 1e-5])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_directory',\n",
    "    project_name='accuracy_based_nn_tuning'\n",
    ")\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    y_pred_fold = (best_model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_test, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len(y_test)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost per instance:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation cost per instance:\", np.std(cost_scores_per_instance))"
   ],
   "id": "865638f5facf1434",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_directory/accuracy_based_nn_tuning/tuner0.json\n",
      "225/225 [==============================] - 0s 501us/step\n",
      "225/225 [==============================] - 0s 962us/step\n",
      "225/225 [==============================] - 0s 436us/step\n",
      "225/225 [==============================] - 0s 537us/step\n",
      "225/225 [==============================] - 0s 543us/step\n",
      "225/225 [==============================] - 0s 480us/step\n",
      "225/225 [==============================] - 0s 472us/step\n",
      "225/225 [==============================] - 0s 570us/step\n",
      "225/225 [==============================] - 0s 711us/step\n",
      "225/225 [==============================] - 0s 1ms/step\n",
      "Mean accuracy: 0.7461358811286449\n",
      "Standard deviation: 0.004299364434950486\n",
      "Mean cost: 10414.2\n",
      "Standard deviation: 464.7538703442931\n",
      "Mean cost per instance: 1.4476230191826522\n",
      "Standard deviation cost per instance: 0.06460298447932904\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Neural network with chosen number of hidden layers (1 and 2)",
   "id": "1ff2ec9a11c59d10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T10:17:50.605674Z",
     "start_time": "2025-01-07T10:13:01.982020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def create_static_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=input_dim, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = create_static_model(X_train_scaled.shape[1])\n",
    "    model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    y_pred_fold = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_test, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len(y_test)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost per instance:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation cost per instance:\", np.std(cost_scores_per_instance))"
   ],
   "id": "263b5fa60742d6a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 806us/step\n",
      "225/225 [==============================] - 0s 414us/step\n",
      "225/225 [==============================] - 0s 544us/step\n",
      "225/225 [==============================] - 0s 464us/step\n",
      "225/225 [==============================] - 0s 442us/step\n",
      "225/225 [==============================] - 0s 463us/step\n",
      "225/225 [==============================] - 0s 447us/step\n",
      "225/225 [==============================] - 0s 485us/step\n",
      "225/225 [==============================] - 0s 415us/step\n",
      "225/225 [==============================] - 0s 772us/step\n",
      "Mean accuracy: 0.751779094346053\n",
      "Standard deviation: 0.0032230170288836844\n",
      "Mean cost: 10296.2\n",
      "Standard deviation: 382.28465833721344\n",
      "Mean cost per instance: 1.431220461495691\n",
      "Standard deviation cost per instance: 0.05313937424759704\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7. Deep learning",
   "id": "7cebeb5f0b0b0546"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T22:21:05.695021Z",
     "start_time": "2025-01-06T22:11:23.864960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "cost_matrix = np.array([[0, 10], [1, 0]])\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
    "\n",
    "# Cross-Validation (Accuracy)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    accuracy_scores.append(scores[1])\n",
    "\n",
    "    y_pred_fold = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len (y_val_fold)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation:\", np.std(cost_scores_per_instance))"
   ],
   "id": "e6337e19be34978b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 426us/step\n",
      "225/225 [==============================] - 0s 428us/step\n",
      "225/225 [==============================] - 0s 427us/step\n",
      "225/225 [==============================] - 0s 431us/step\n",
      "225/225 [==============================] - 0s 557us/step\n",
      "225/225 [==============================] - 0s 466us/step\n",
      "225/225 [==============================] - 0s 443us/step\n",
      "225/225 [==============================] - 0s 435us/step\n",
      "225/225 [==============================] - 0s 427us/step\n",
      "225/225 [==============================] - 0s 474us/step\n",
      "Mean accuracy: 0.7505976021289825\n",
      "Standard deviation: 0.005213053811480142\n",
      "Mean cost: 10561.2\n",
      "Standard deviation: 510.5698385137924\n",
      "Mean cost: 1.4680567139282734\n",
      "Standard deviation: 0.07097162058851716\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 8. SVM",
   "id": "8caadd8184a33821"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:51:30.858454Z",
     "start_time": "2025-01-06T21:51:29.869300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "cost_matrix = np.array([[0, 10], [1, 0]])\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "svm_clf = LinearSVC(dual=False, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(X_balanced, y_balanced):\n",
    "    X_train_fold, X_val_fold = X_balanced.iloc[train_index], X_balanced.iloc[test_index]\n",
    "    y_train_fold, y_val_fold = y_balanced.iloc[train_index], y_balanced.iloc[test_index]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train_fold.copy()\n",
    "    X_val_scaled = X_val_fold.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train_fold[columns_to_normalize])\n",
    "    X_val_scaled[columns_to_normalize] = scaler.transform(X_val_fold[columns_to_normalize])\n",
    "\n",
    "    svm_clf.fit(X_train_scaled, y_train_fold)\n",
    "\n",
    "    y_pred_fold = svm_clf.predict(X_val_scaled)\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_val_fold, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len (y_val_fold)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation:\", np.std(cost_scores_per_instance))"
   ],
   "id": "6d2e9ceac384e89f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7448709613041367\n",
      "Standard deviation: 0.005344461520723734\n",
      "Mean cost: 10914.7\n",
      "Standard deviation: 248.00687490470904\n",
      "Mean cost: 1.5171948846260772\n",
      "Standard deviation: 0.03447412773209746\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Cost-based performance"
   ],
   "id": "bb8fed6ef0f63a75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Naive Bayes",
   "id": "efd9f94e7fe3178c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:47:27.692922Z",
     "start_time": "2025-01-06T21:47:26.990883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "total = np.sum(cost_matrix)\n",
    "class_prior = [np.sum(cost_matrix[:, 0]) / total, np.sum(cost_matrix[:, 1]) / total]\n",
    "\n",
    "columns_to_normalize = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                        'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "                        'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "                        'Income']\n",
    "\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "nb_model = GaussianNB(priors=class_prior)\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred_fold = nb_model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_test, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len (y_val_fold)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation:\", np.std(cost_scores_per_instance))"
   ],
   "id": "4da5a80906d36cf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6829200845504216\n",
      "Standard deviation: 0.006260065663740211\n",
      "Mean cost: 5515.8\n",
      "Standard deviation: 184.18349546036964\n",
      "Mean cost: 0.7667222685571309\n",
      "Standard deviation: 0.025602376349787254\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Neural network (automatic)",
   "id": "79d385c59a200739"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T00:42:21.187595Z",
     "start_time": "2025-01-07T00:34:11.289523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_input', min_value=32, max_value=128, step=32),\n",
    "                    input_dim=X_train_scaled.shape[1],\n",
    "                    activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('num_hidden_layers', 1, 3)):\n",
    "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=128, step=32),\n",
    "                        activation='relu'))\n",
    "        model.add(Dropout(hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 1e-4, 1e-5])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_directory',\n",
    "    project_name='cost_based_nn_tuning'\n",
    ")\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    y_pred_fold = (best_model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_test, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len(y_test)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost per instance:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation cost per instance:\", np.std(cost_scores_per_instance))"
   ],
   "id": "5cf0fb8ac24e34e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/_rwxvf5n6f937nqksfgj4sg00000gn/T/ipykernel_5792/2036249598.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 454us/step\n",
      "225/225 [==============================] - 0s 475us/step\n",
      "225/225 [==============================] - 0s 494us/step\n",
      "225/225 [==============================] - 0s 509us/step\n",
      "225/225 [==============================] - 0s 513us/step\n",
      "225/225 [==============================] - 0s 536us/step\n",
      "225/225 [==============================] - 0s 466us/step\n",
      "225/225 [==============================] - 0s 524us/step\n",
      "225/225 [==============================] - 0s 498us/step\n",
      "225/225 [==============================] - 0s 469us/step\n",
      "Mean accuracy: 0.7469002583613903\n",
      "Standard deviation: 0.005928988980732573\n",
      "Mean cost: 10055.0\n",
      "Standard deviation: 488.8218489388542\n",
      "Mean cost per instance: 1.3976925215457325\n",
      "Standard deviation cost per instance: 0.06794854725310737\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Neural network (not automatic)",
   "id": "a9d21ed3f1e5308a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T00:46:16.617650Z",
     "start_time": "2025-01-07T00:42:21.191698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def create_static_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=input_dim, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = create_static_model(X_train_scaled.shape[1])\n",
    "    model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    y_pred_fold = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_test, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len(y_test)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost per instance:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation cost per instance:\", np.std(cost_scores_per_instance))"
   ],
   "id": "eb7a721ec4118387",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 403us/step\n",
      "225/225 [==============================] - 0s 400us/step\n",
      "225/225 [==============================] - 0s 420us/step\n",
      "225/225 [==============================] - 0s 433us/step\n",
      "225/225 [==============================] - 0s 412us/step\n",
      "225/225 [==============================] - 0s 424us/step\n",
      "225/225 [==============================] - 0s 412us/step\n",
      "225/225 [==============================] - 0s 400us/step\n",
      "225/225 [==============================] - 0s 442us/step\n",
      "225/225 [==============================] - 0s 418us/step\n",
      "Mean accuracy: 0.7511118851842213\n",
      "Standard deviation: 0.005019265558982593\n",
      "Mean cost: 10590.8\n",
      "Standard deviation: 516.6005807197665\n",
      "Mean cost per instance: 1.4721712538226301\n",
      "Standard deviation cost per instance: 0.07180992225740426\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7. Deep learning",
   "id": "774fd7c7ba89170b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T23:56:15.861830Z",
     "start_time": "2025-01-06T23:46:26.025944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "cost_matrix = np.array([[0, 10], [1, 0]])\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "\n",
    "healthy_df = df[df['Diabetes_binary'] == 0]\n",
    "diabetic_df = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "healthy_sampled = healthy_df.sample(frac=0.2, random_state=42)\n",
    "diabetic_sampled = diabetic_df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([healthy_sampled, diabetic_sampled])\n",
    "\n",
    "X_balanced = balanced_df.drop(columns=['Diabetes_binary'])\n",
    "y_balanced = balanced_df['Diabetes_binary']\n",
    "\n",
    "columns_to_normalize = [\n",
    "    'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "    'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "    'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', \n",
    "    'Education', 'Income'\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cost_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy')\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    y_pred_fold = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation of accuracy:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation of cost:\", np.std(cost_scores))\n",
    "total_instances = len(y_balanced)\n",
    "cost_scores_per_instance = [x / total_instances for x in cost_scores]\n",
    "print(\"Mean cost per instance:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation of cost per instance:\", np.std(cost_scores_per_instance))"
   ],
   "id": "dd8ae824a8b04de5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 628us/step\n",
      "225/225 [==============================] - 0s 522us/step\n",
      "225/225 [==============================] - 0s 606us/step\n",
      "225/225 [==============================] - 0s 542us/step\n",
      "225/225 [==============================] - 0s 378us/step\n",
      "225/225 [==============================] - 0s 538us/step\n",
      "225/225 [==============================] - 0s 396us/step\n",
      "225/225 [==============================] - 0s 494us/step\n",
      "225/225 [==============================] - 0s 472us/step\n",
      "225/225 [==============================] - 0s 402us/step\n",
      "Mean accuracy: 0.7497218881536483\n",
      "Standard deviation of accuracy: 0.005162848290429181\n",
      "Mean cost: 10689.9\n",
      "Standard deviation of cost: 352.56331346298634\n",
      "Mean cost per instance: 0.14858640053374844\n",
      "Standard deviation of cost per instance: 0.004900524205812667\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 8. SVM",
   "id": "4cd443232aecf369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:50:02.282067Z",
     "start_time": "2025-01-06T21:50:01.200296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "class_weights = {0: 1, 1: 10}\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "cost_scores = []\n",
    "\n",
    "svm_clf = LinearSVC(dual=False, random_state=42, class_weight=class_weights)\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_balanced, y_balanced):\n",
    "    X_train, X_test = X_balanced.iloc[train_idx], X_balanced.iloc[test_idx]\n",
    "    y_train, y_test = y_balanced.iloc[train_idx], y_balanced.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "    X_test_scaled[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "    svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred_fold = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_test, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_fold)\n",
    "    cost = np.sum(confusion_mat * np.transpose(cost_matrix))\n",
    "    cost_scores.append(cost)\n",
    "\n",
    "print(\"Mean accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard deviation:\", np.std(accuracy_scores))\n",
    "print(\"Mean cost:\", np.mean(cost_scores))\n",
    "print(\"Standard deviation:\", np.std(cost_scores))\n",
    "divisor = len (y_val_fold)\n",
    "cost_scores_per_instance = [x / divisor for x in cost_scores]\n",
    "print(\"Mean cost:\", np.mean(cost_scores_per_instance))\n",
    "print(\"Standard deviation:\", np.std(cost_scores_per_instance))"
   ],
   "id": "1d872657e8d3d080",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.5237684461396774\n",
      "Standard deviation: 0.004372030459279511\n",
      "Mean cost: 3647.6\n",
      "Standard deviation: 40.7852914664098\n",
      "Mean cost: 0.5070336391437309\n",
      "Standard deviation: 0.00566934827167219\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
